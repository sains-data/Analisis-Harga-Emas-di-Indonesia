version: '3.8'

services:
  namenode:
    build: 
      context: .
      dockerfile: Dockerfile.namenode
    container_name: namenode
    ports:
      - "9870:9870"
      - "8020:8020"
    environment:
      - CLUSTER_NAME=hadoop_cluster
    volumes:
      - ./dataset:/opt/dataset
      - ./scripts:/opt/scripts

  datanode:
    build:
      context: .
      dockerfile: Dockerfile.datanode
    container_name: datanode
    depends_on:
      - namenode
    volumes:
      - ./dataset:/opt/dataset

  hive-metastore-db:
    image: postgres:13
    container_name: hive-metastore-db
    environment:
      POSTGRES_DB: hive_metastore
      POSTGRES_USER: hive
      POSTGRES_PASSWORD: hive123
    volumes:
      - hive_metastore_db:/var/lib/postgresql/data

  hive-metastore:
    image: apache/hive:3.1.3
    container_name: hive-metastore
    depends_on:
      - hive-metastore-db
      - namenode
    environment:
      SERVICE_NAME: metastore
      DB_DRIVER: postgres
      SERVICE_OPTS: "-Djavax.jdo.option.ConnectionDriverName=org.postgresql.Driver -Djavax.jdo.option.ConnectionURL=jdbc:postgresql://hive-metastore-db:5432/hive_metastore -Djavax.jdo.option.ConnectionUserName=hive -Djavax.jdo.option.ConnectionPassword=hive123"
    ports:
      - "9083:9083"

  hiveserver2:
    image: apache/hive:3.1.3
    container_name: hiveserver2
    depends_on:
      - hive-metastore
    environment:
      SERVICE_NAME: hiveserver2
      SERVICE_OPTS: "-Dhive.metastore.uris=thrift://hive-metastore:9083"
      IS_RESUME: "true"
    ports:
      - "10000:10000"
      - "10002:10002"
    volumes:
      - ./scripts:/opt/scripts

  spark-master:
    image: bitnami/spark:3.4
    container_name: spark-master
    ports:
      - "8080:8080"
      - "7077:7077"
    environment:
      - SPARK_MODE=master
    volumes:
      - ./dataset:/opt/dataset
      - ./scripts:/opt/scripts

  spark-worker:
    image: bitnami/spark:3.4
    container_name: spark-worker
    depends_on:
      - spark-master
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
    volumes:
      - ./dataset:/opt/dataset
      - ./scripts:/opt/scripts

volumes:
  hive_metastore_db: